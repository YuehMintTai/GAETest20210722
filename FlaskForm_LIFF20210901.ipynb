{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FlaskForm@LIFF20210901.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPZsArZZp7rciZDM0qVr3JU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YuehMintTai/GAETest20210722/blob/main/FlaskForm_LIFF20210901.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8RZawPHUvP1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e26f642e-d13f-422d-a72a-32f7d3e98d52"
      },
      "source": [
        "!pip install flask_ngrok\n",
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece\n",
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flask_ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (1.1.4)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.0.1)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask_ngrok) (2.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2021.5.30)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n",
            "Collecting bert-for-tf2\n",
            "  Downloading bert-for-tf2-0.14.9.tar.gz (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 148 kB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading py-params-0.10.2.tar.gz (7.4 kB)\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading params-flow-0.8.2.tar.gz (22 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.62.0)\n",
            "Building wheels for collected packages: bert-for-tf2, params-flow, py-params\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-py3-none-any.whl size=30534 sha256=012439ed64e9dcf092ffe4429c4f85c1c22a349081754c57b7dda694a2b60586\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/b6/e5/8c76ec779f54bc5c2f1b57d2200bb9c77616da83873e8acb53\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-py3-none-any.whl size=19473 sha256=85eb75983576d0391e33467e8ca40206c5dd159c5e87b3faf9ceda8f8680e830\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/fc/d2/a44fff33af0f233d7def6e7de413006d57c10e10ad736fe8f5\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.10.2-py3-none-any.whl size=7912 sha256=f6e9aed9fa4b6c096316890670a44124571cd729cee321bfaed14dade877218b\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/11/67/33cc51bbee127cb8fb2ba549cd29109b2f22da43ddf9969716\n",
            "Successfully built bert-for-tf2 params-flow py-params\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 6.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.10.0-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting huggingface-hub>=0.0.12\n",
            "  Downloading huggingface_hub-0.0.16-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.9 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 59.8 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 45.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 51.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.16 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YRGOp7o2r3l",
        "outputId": "b9487974-326a-4d7e-fc32-171723f25170"
      },
      "source": [
        "!unzip BERT_20210830_Psychotic_depression_model.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  BERT_20210830_Psychotic_depression_model.zip\n",
            "   creating: BERT_20210830_Psychotic_depression_model/assets/\n",
            "  inflating: BERT_20210830_Psychotic_depression_model/keras_metadata.pb  \n",
            "  inflating: BERT_20210830_Psychotic_depression_model/saved_model.pb  \n",
            "   creating: BERT_20210830_Psychotic_depression_model/variables/\n",
            "  inflating: BERT_20210830_Psychotic_depression_model/variables/variables.index  \n",
            "  inflating: BERT_20210830_Psychotic_depression_model/variables/variables.data-00000-of-00001  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzqWKdB78_-e",
        "outputId": "cc199a73-e24d-4ef7-ebee-d8dbc2eb117a"
      },
      "source": [
        "##AI form (condensed)\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask,request,jsonify, render_template\n",
        "from datetime import datetime\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "import bert \n",
        "import os\n",
        "import numpy\n",
        "app=Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "BertTokenizer=bert.bert_tokenization.FullTokenizer\n",
        "bert_layer=hub.KerasLayer('https://tfhub.dev/tensorflow/bert_zh_L-12_H-768_A-12/2',trainable=False)\n",
        "vocabulary_file=bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "to_lower_case=bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer=BertTokenizer(vocabulary_file,to_lower_case)\n",
        "max_len=500\n",
        "BATCH_SIZE=100\n",
        "new_model=tf.keras.models.load_model('BERT_20210830_Psychotic_depression_model')\n",
        "\n",
        "@app.route('/',methods=['POST','GET'])\n",
        "def index():\n",
        "  title=\"輸入病史資料(建議100字以上)\"+str(datetime.today())\n",
        "  myText=request.form.get('myHistory')\n",
        "  if myText:\n",
        "    myText_bert=tokenizer.convert_tokens_to_ids(tokenizer.tokenize(str(myText)))\n",
        "    test_sorted_text_labels=[(myText_bert[:max_len])]\n",
        "    test_processed=tf.data.Dataset.from_generator(lambda:test_sorted_text_labels,output_types=(tf.int32))\n",
        "    test_batched=test_processed.padded_batch(BATCH_SIZE,padded_shapes=((max_len,)))\n",
        "    result=new_model.predict(test_batched)\n",
        "    myPredict=round(result[0][0],5)\n",
        "  else:\n",
        "    myPredict=0\n",
        "  ##myPredict='50%'\n",
        "  return render_template(\"index.html\",title=title,myHx=myText,myPredict=myPredict)\n",
        "\n",
        "app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug: * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://31a4-35-233-193-0.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [03/Sep/2021 14:53:26] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Sep/2021 14:53:27] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Sep/2021 14:53:31] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Sep/2021 14:53:39] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Sep/2021 14:53:47] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Sep/2021 14:53:51] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vyaDIh1HHCz",
        "outputId": "2a964996-35d4-4422-ec9c-184b3b565d4b"
      },
      "source": [
        "##AI form (too complicate)\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask,request,jsonify, render_template\n",
        "from datetime import datetime\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "import bert \n",
        "import os\n",
        "import numpy\n",
        "app=Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "class TEXT_Model(tf.keras.Model):\n",
        "  def __init__(self,vocaulary_size,embedding_dimensions=128,\n",
        "               cnn_filters=50, dnn_units=512,\n",
        "               model_output_classes=2, dropout_rate=0.1,\n",
        "               training=False,name='text_model'):\n",
        "    super(TEXT_MODEL,self).__init__(name=name)\n",
        "    self.embedding=layers.Embedding(vocaulary_size,embedding_dimensions)\n",
        "    self.cnn_layer1=layers.Conv1D(filters=cnn_filters,kernel_size=2,padding='valid',activation='relu')\n",
        "    self.cnn_layer2=layers.Conv1D(filters=cnn_filters,kernel_size=3,padding='valid',activation='relu')\n",
        "    self.cnn_layer3=layers.Conv1D(filters=cnn_filters,kernel_size=4,padding='valid',activation='relu')\n",
        "    self.pool=layers.GlobalMaxPool1D()\n",
        "    self.dense_1=layers.Dense(units=dnn_units, activation='relu')\n",
        "    self.dropout=layers.Dropout(rate=dropout_rate)\n",
        "    self.last_dense=layers.Dense(units=1,activation='sigmoid')\n",
        "  def call(self,inputs,training):\n",
        "    l =self.embedding(input)\n",
        "    l_1=self.cnn_layer1(l)\n",
        "    l_1=self.poot(l_1)\n",
        "    l_2=self.cnn_layer2(l)\n",
        "    l_2=self.pool(l_2)\n",
        "    l_3=self.cnn_layer3(l)\n",
        "    l_3=self.pool(l_3)\n",
        "    concatenated=tf.concat([l_1,l_2,l_3], axis=-1)\n",
        "    concatenated=self.dense_1(concatnated)\n",
        "    concatenated=self.dropout(concatenated,training)\n",
        "    model_output=self.last_dense(concatenated)\n",
        "    return model_output\n",
        "\n",
        "  def tokenize_text(text_input):\n",
        "    return tokenizer.convert_tokens_to_ids(tokenizer.toknize(text_input))\n",
        "\n",
        "BertTokenizer=bert.bert_tokenization.FullTokenizer\n",
        "if os.path.isdir('bert_zh_L-12_H-768_A-12_2'):\n",
        "  bert_layer=hub.KerasLayer('bert_zh_L-12_H-768_A-12_2', trainable=False)\n",
        "else:\n",
        "  bert_layer=hub.KerasLayer('https://tfhub.dev/tensorflow/bert_zh_L-12_H-768_A-12/2',trainable=False)\n",
        "vocabulary_file=bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "to_lower_case=bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer=BertTokenizer(vocabulary_file,to_lower_case)\n",
        "max_len=500\n",
        "BATCH_SIZE=100\n",
        "new_model=tf.keras.models.load_model('BERT_20210830_Psychotic_depression_model')\n",
        "\n",
        "@app.route('/',methods=['POST','GET'])\n",
        "def index():\n",
        "  title=\"輸入病史資料(建議100字以上)\"+str(datetime.today())\n",
        "  myText=request.form.get('myHistory')\n",
        "  if myText:\n",
        "    #myText_bert=tokenize_text(str(myText))\n",
        "    myText_bert=tokenizer.convert_tokens_to_ids(tokenizer.tokenize(str(myText)))\n",
        "    test_sorted_text_labels=[(myText_bert[:max_len])]\n",
        "    test_processed=tf.data.Dataset.from_generator(lambda:test_sorted_text_labels,output_types=(tf.int32))\n",
        "    test_batched=test_processed.padded_batch(BATCH_SIZE,padded_shapes=((max_len,)))\n",
        "    result=new_model.predict(test_batched)\n",
        "    myPredict=round(result[0][0],5)\n",
        "  else:\n",
        "    myPredict=0\n",
        "  ##myPredict='50%'\n",
        "  return render_template(\"index.html\",title=title,myHx=myText,myPredict=myPredict)\n",
        "\n",
        "\n",
        "app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
            "INFO:werkzeug: * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://03af-35-204-175-255.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [01/Sep/2021 15:18:30] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [01/Sep/2021 15:18:30] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 15:18:30] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [01/Sep/2021 15:18:30] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [01/Sep/2021 15:18:33] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [01/Sep/2021 15:18:33] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 15:18:51] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [01/Sep/2021 15:18:51] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 15:20:33] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [01/Sep/2021 15:20:33] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 15:20:55] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [01/Sep/2021 15:20:55] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlvK4h_wU2GG",
        "outputId": "33e35e95-0bd7-490b-d55b-93240bc1f8b7"
      },
      "source": [
        "##BASIC no Form\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask \n",
        "from datetime import date\n",
        "\n",
        "app=Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "  return '歡迎使用三總北投門診助手,現在時間是{}'.format(str(date.today()))\n",
        "\n",
        "app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://169f-35-221-198-146.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [01/Sep/2021 07:50:39] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 07:50:40] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [01/Sep/2021 07:51:26] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 07:55:31] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        }
      ]
    }
  ]
}