{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FlaskForm@LIFF20210901.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNduRa+xdMfiFeUtWV7fA5A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YuehMintTai/GAETest20210722/blob/main/FlaskForm_LIFF20210901.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8RZawPHUvP1"
      },
      "source": [
        "!pip install flask_ngrok\n",
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vyaDIh1HHCz",
        "outputId": "a34d86dd-467e-4aeb-e7d5-c5b06d907cf8"
      },
      "source": [
        "##Simple form\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask,request,jsonify, render_template\n",
        "from datetime import datetime\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "import bert \n",
        "import os\n",
        "import numpy\n",
        "app=Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "class TEXT_Model(tf.keras.Model):\n",
        "  def __init__(self,vocaulary_size,embedding_dimensions=128,\n",
        "               cnn_filters=50, dnn_units=512,\n",
        "               model_output_classes=2, dropout_rate=0.1,\n",
        "               training=False,name='text_model'):\n",
        "    super(TEXT_MODEL,self).__init__(name=name)\n",
        "    self.embedding=layers.Embedding(vocaulary_size,embedding_dimensions)\n",
        "    self.cnn_layer1=layers.Conv1D(filters=cnn_filters,kernel_size=2,padding='valid',activation='relu')\n",
        "    self.cnn_layer2=layers.Conv1D(filters=cnn_filters,kernel_size=3,padding='valid',activation='relu')\n",
        "    self.cnn_layer3=layers.Conv1D(filters=cnn_filters,kernel_size=4,padding='valid',activation='relu')\n",
        "    self.pool=layers.GlobalMaxPool1D()\n",
        "    self.dense_1=layers.Dense(units=dnn_units, activation='relu')\n",
        "    self.dropout=layers.Dropout(rate=dropout_rate)\n",
        "    self.last_dense=layers.Dense(units=1,activation='sigmoid')\n",
        "  def call(self,inputs,training):\n",
        "    l =self.embedding(input)\n",
        "    l_1=self.cnn_layer1(l)\n",
        "    l_1=self.poot(l_1)\n",
        "    l_2=self.cnn_layer2(l)\n",
        "    l_2=self.pool(l_2)\n",
        "    l_3=self.cnn_layer3(l)\n",
        "    l_3=self.pool(l_3)\n",
        "    concatenated=tf.concat([l_1,l_2,l_3], axis=-1)\n",
        "    concatenated=self.dense_1(concatnated)\n",
        "    concatenated=self.dropout(concatenated,training)\n",
        "    model_output=self.last_dense(concatenated)\n",
        "    return model_output\n",
        "  def tokenize_text(text_input):\n",
        "    return tokenizer.convert_tokens_to_ids(tokenizer.toknize(text_input))\n",
        "\n",
        "BertTokenizer=bert.bert_tokenization.FullTokenizer\n",
        "if os.path.isdir('bert_zh_L-12_H-768_A-12_2'):\n",
        "  bert_layer=hub.KerasLayer('bert_zh_L-12_H-768_A-12_2', trainable=False)\n",
        "else:\n",
        "  bert_alyer=hub.KerasLayer('https://tfhub.dev/tensorflow/bert_zh_L-12-H-768_A-12/2',trainable=False)\n",
        "vocabulary_file=bert_layer.resolved_object.vocal_file.asset_path.numpy()\n",
        "to_lower_case=bert.layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer=BertTokenizer(vocabulary_file,to_lower_case)\n",
        "max_len=500\n",
        "BATCH_SIZE=100\n",
        "\n",
        "\n",
        "@app.route('/',methods=['POST','GET'])\n",
        "def index():\n",
        "  title=\"輸入病史資料(建議100字以上)\"+str(datetime.today())\n",
        "  myText=request.form.get('myHistory')\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  myPredict='50%'\n",
        "  return render_template(\"index.html\",title=title,myHx=myText,myPredict=myPredict)\n",
        "\n",
        "\n",
        "app.run()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://2728-35-204-175-255.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlvK4h_wU2GG",
        "outputId": "33e35e95-0bd7-490b-d55b-93240bc1f8b7"
      },
      "source": [
        "##BASIC no Form\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask \n",
        "from datetime import date\n",
        "\n",
        "app=Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "  return '歡迎使用三總北投門診助手,現在時間是{}'.format(str(date.today()))\n",
        "\n",
        "app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://169f-35-221-198-146.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [01/Sep/2021 07:50:39] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 07:50:40] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [01/Sep/2021 07:51:26] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [01/Sep/2021 07:55:31] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        }
      ]
    }
  ]
}